backend: llama
context_size: 1024
name: open-llama-7B-open-instruct
parameters:
  model: open-llama-7B-open-instruct
  temperature: 0.2
  top_k: 80
  top_p: 0.7
template:
  chat: gpt4all-chat
  completion: gpt4all-completion
