## Set number of threads.
## Note: prefer the number of physical cores. Overbooking the CPU degrades performance notably.
# THREADS=8

## Specify a different bind address (defaults to ":8080")
# ADDRESS=127.0.0.1:8080

## CORS settings
# CORS=true
# CORS_ALLOW_ORIGINS=*

## Default models context size
# CONTEXT_SIZE=1024

## Default path for models
# MODELS_PATH=/models

## Enable debug mode
# DEBUG=true

## Specify a build type. Available: cublas, openblas.
# BUILD_TYPE=openblas

## Enable go tags, available: stablediffusion, tts
## stablediffusion: image generation with stablediffusion
## tts: enables text-to-speech with go-piper 
## (requires REBUILD=true)
#
# GO_TAGS=stablediffusion

## Uncomment and set to false to disable rebuilding from source
# REBUILD=true

## Path where to store generated images
# IMAGE_PATH=/tmp

## Specify a default upload limit in MB (whisper)
# UPLOAD_LIMIT

## Define galleries.
## models will to install will be visible in `/models/available`
# GALLERIES=[{"name":"model-gallery", "url":"github:go-skynet/model-gallery/index.yaml"}]

## This should start a model download on boot.
# PRELOAD_MODELS=[{"url": "https://raw.githubusercontent.com/go-skynet/model-gallery/main/gpt4all-j.yaml", "name": "ggml-gpt4all-j"}]

## Chatbot-UI settings #################################
# Specify a fake API key
# OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXXXXXX
# # Specify the URL of the API backend
# OPENAI_API_HOST='http://api:8080'
# # Specify the default model to use
# DEFAULT_MODEL=ggml-gpt4all-j